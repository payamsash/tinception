{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pyspark\n",
    "import dxpy\n",
    "import dxdata\n",
    "!which java"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# spark initialization\n",
    "sc = pyspark.SparkContext()\n",
    "spark = pyspark.sql.SparkSession(sc)\n",
    "\n",
    "# find dispensed database name and dataset id\n",
    "dispensed_database = dxpy.find_one_data_object(\n",
    "    classname='database', \n",
    "    name='app*', \n",
    "    folder='/', \n",
    "    name_mode='glob', \n",
    "    describe=True)\n",
    "dispensed_database_name = dispensed_database['describe']['name']\n",
    "\n",
    "dispensed_dataset = dxpy.find_one_data_object(\n",
    "    typename='Dataset', \n",
    "    name='app*.dataset', \n",
    "    folder='/', \n",
    "    name_mode='glob')\n",
    "dispensed_dataset_id = dispensed_dataset['id']\n",
    "\n",
    "dataset = dxdata.load_dataset(id=dispensed_dataset_id)\n",
    "participant = dataset['participant']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some helper functions to get field IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def fields_for_id(field_id):\n",
    "    from distutils.version import LooseVersion\n",
    "    field_id = str(field_id)\n",
    "    fields = participant.find_fields(name_regex=r'^p{}(_i\\d+)?(_a\\d+)?$'.format(field_id))\n",
    "    return sorted(fields, key=lambda f: LooseVersion(f.name))\n",
    "\n",
    "def field_names_for_id(field_id):\n",
    "    return [f.name for f in fields_for_id(field_id)]\n",
    "\n",
    "def fields_by_title_keyword(keyword):\n",
    "    from distutils.version import LooseVersion\n",
    "    fields = list(participant.find_fields(lambda f: keyword.lower() in f.title.lower()))\n",
    "    return sorted(fields, key=lambda f: LooseVersion(f.name))\n",
    "\n",
    "def field_names_by_title_keyword(keyword):\n",
    "    return [f.name for f in fields_by_title_keyword(keyword)]\n",
    "\n",
    "def field_titles_by_title_keyword(keyword):\n",
    "    return [f.title for f in fields_by_title_keyword(keyword)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get selected field IDs from dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "match_variables = [\n",
    "                    'sex_f31_0_0', 'age_when_attended_assessment_centre_f21003_0_0',\n",
    "                    'uk_biobank_assessment_centre_f54_2_0', 'uk_biobank_assessment_centre_f54_3_0',\n",
    "                    'loud_music_exposure_frequency_f4836_0_0',\n",
    "                    'noisy_workplace_f4825_0_0', 'cochlear_implant_f4792_0_0',\n",
    "                    'hearing_aid_user_f3393_0_0', 'hearing_difficultyproblems_with_background_noise_f2257_0_0',\n",
    "                    'handedness_chiralitylaterality_f1707_0_0', 'alcohol_intake_frequency_f1558_0_0',\n",
    "                    'average_total_household_income_before_tax_f738_0_0',\n",
    "                    'speechreceptionthreshold_srt_estimate_left_f20019_0_0',\n",
    "                    'speechreceptionthreshold_srt_estimate_right_f20021_0_0'\n",
    "                    ]\n",
    "\n",
    "tinnitus_field_ids = ['p4803_i0', 'p4803_i2', 'p4814_i0', 'p28625'] # added extra tinnitus\n",
    "\n",
    "mr_variables = ['p26501_i2', 'p26501_i3'] # to see if they exist\n",
    "\n",
    "demographic_field_ids = [\n",
    "                        'eid',\n",
    "                        'p31', 'p21003_i0',\n",
    "                        'p54_i2', 'p54_i3',\n",
    "                        'p4836_i0',\n",
    "                        'p4825_i0', 'p4792_i0',\n",
    "                        'p3393_i0', 'p2257_i0',\n",
    "                        'p1707_i0', 'p1558_i0',\n",
    "                        'p738_i0',\n",
    "                        'p20019_i0', 'p20021_i0'\n",
    "                        ] + \\\n",
    "                        tinnitus_field_ids + \\\n",
    "                        mr_variables\n",
    "\n",
    "df = participant.retrieve_fields(\n",
    "        names=demographic_field_ids,\n",
    "        engine=dxdata.connect()\n",
    "    )\n",
    "df.toPandas().to_csv('ukb_demographics.csv', index=False)\n",
    "!dx upload ukb_demographics.csv --dest / "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assuming you have the ukb_demographics.csv, let's prepare columns to be ready for matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "## read file\n",
    "df = pd.read_csv(\"ukb_demographics.csv\")\n",
    "\n",
    "## map column names\n",
    "match_variables = [\n",
    "                    'sex_f31_0_0', 'age_when_attended_assessment_centre_f21003_0_0',\n",
    "                    'uk_biobank_assessment_centre_f54_2_0', 'uk_biobank_assessment_centre_f54_3_0',\n",
    "                    'loud_music_exposure_frequency_f4836_0_0',\n",
    "                    'noisy_workplace_f4825_0_0', 'cochlear_implant_f4792_0_0',\n",
    "                    'hearing_aid_user_f3393_0_0', 'hearing_difficultyproblems_with_background_noise_f2257_0_0',\n",
    "                    'handedness_chiralitylaterality_f1707_0_0', 'alcohol_intake_frequency_f1558_0_0',\n",
    "                    'average_total_household_income_before_tax_f738_0_0',\n",
    "                    'speechreceptionthreshold_srt_estimate_left_f20019_0_0',\n",
    "                    'speechreceptionthreshold_srt_estimate_right_f20021_0_0'\n",
    "                    ]\n",
    "tinnitus_field_names = ['tin_status_1', 'tin_status_2', 'tin_severity', 'tin_duration']\n",
    "new_col_names = [\"subject_id\", \"sex\", \"age\", \"center_v2\", \"center_v3\"] + \\\n",
    "            [re.split(r'_f\\d+', s)[0] for s in match_variables[4:]] + \\\n",
    "            tinnitus_field_names + \\\n",
    "            [\"Mean_intensity_v2\", \"Mean_intensity_v3\"]\n",
    "\n",
    "\n",
    "mapping = dict(zip(\n",
    "                list(df.columns),\n",
    "                new_col_names\n",
    "                ))\n",
    "df.rename(columns=mapping, inplace=True)\n",
    "\n",
    "## fixing tinnitus status\n",
    "cols = [\"tin_status_1\", \"tin_status_2\"]\n",
    "mapping = {0: 0, 11: 1}\n",
    "df[cols] = df[cols].apply(lambda s: s.map(mapping))\n",
    "df = df.dropna(subset=cols, how=\"all\")\n",
    "df = df[\n",
    "    (df[\"tin_status_1\"] == df[\"tin_status_2\"]) |\n",
    "    (df[\"tin_status_1\"].isna()) |\n",
    "    (df[\"tin_status_2\"].isna())\n",
    "]\n",
    "\n",
    "df[\"tin_status\"] = df[\"tin_status_1\"].combine_first(df[\"tin_status_2\"])\n",
    "df = df.drop(columns=[\"tin_status_1\", \"tin_status_2\"])\n",
    "\n",
    "## HL fix\n",
    "col = 'hearing_difficultyproblems_with_background_noise'\n",
    "df[col] = df[col].map({0: 0, 1: 1})\n",
    "df.dropna(subset=[col], inplace=True)\n",
    "\n",
    "## helper function to clean the df\n",
    "def replace_and_fill_mode(df, column, to_replace=None):\n",
    "    \"\"\"\n",
    "    Replace specific values with NaN and fill missing values with the mode.\n",
    "    \n",
    "    Parameters:\n",
    "        df: pandas DataFrame\n",
    "        column: column name as string\n",
    "        to_replace: list of values to replace with NaN (default ['Prefer not to answer', 'Do not know'])\n",
    "    \"\"\"\n",
    "    if to_replace is None:\n",
    "        to_replace = ['Prefer not to answer', 'Do not know']\n",
    "    \n",
    "    df[column].replace(to_replace, pd.NA, inplace=True)\n",
    "    df[column].fillna(df[column].mode()[0], inplace=True)\n",
    "\n",
    "# apply the helper function on these columns\n",
    "replace_fill_cols = {\n",
    "    'handedness_chiralitylaterality': ['Prefer not to answer'],\n",
    "    'average_total_household_income_before_tax': ['Prefer not to answer', 'Do not know'],\n",
    "    'loud_music_exposure_frequency': ['Prefer not to answer', 'Do not know'],\n",
    "    'noisy_workplace': ['Prefer not to answer', 'Do not know'],\n",
    "    'cochlear_implant': ['Prefer not to answer'],\n",
    "    'hearing_aid_user': ['Prefer not to answer'],\n",
    "    'hearing_difficultyproblems_with_background_noise': ['Prefer not to answer', 'Do not know'],\n",
    "    'alcohol_intake_frequency': ['Prefer not to answer']\n",
    "}\n",
    "\n",
    "for col, values in replace_fill_cols.items():\n",
    "    replace_and_fill_mode(df, col, to_replace=values)\n",
    "\n",
    "# drop rows with missing critical data\n",
    "df.dropna(subset=[\n",
    "    'speechreceptionthreshold_srt_estimate_left',\n",
    "    'speechreceptionthreshold_srt_estimate_right'\n",
    "    ], how='any', inplace=True)\n",
    "\n",
    "## get only subjects that have MRI at least in one visit\n",
    "df.dropna(subset=[\"Mean_intensity_v2\", \"Mean_intensity_v3\"], how='all', inplace=True)\n",
    "\n",
    "## save\n",
    "df.to_csv(\"ukb_demographics_ready_for_matching.csv\", index=False)\n",
    "!dx upload ukb_demographics_ready_for_matching.csv --dest / "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matching in R (change the Kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "install.packages(\"MatchIt\")\n",
    "install.packages(\"cobalt\")\n",
    "install.packages(\"gtsummary\")\n",
    "install.packages(\"broom\", repos = \"https://cloud.r-project.org\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "rm(list = ls())\n",
    "cat(\"\\014\")\n",
    "\n",
    "library(MatchIt)\n",
    "library(dplyr)\n",
    "library(tidyr)\n",
    "library(cobalt)\n",
    "library(gtsummary)\n",
    "\n",
    "## load data\n",
    "dat <- read.csv(\"ukb_demographics_ready_for_matching.csv\")\n",
    "\n",
    "# define matching variables\n",
    "match_vars <- c(\n",
    "  \"sex\",\n",
    "  \"age\",\n",
    "  \"loud_music_exposure_frequency\",\n",
    "  \"noisy_workplace\",\n",
    "  \"hearing_aid_user\",\n",
    "  \"hearing_difficultyproblems_with_background_noise\",\n",
    "  \"handedness_chiralitylaterality\",\n",
    "  \"alcohol_intake_frequency\",\n",
    "  \"average_total_household_income_before_tax\",\n",
    "  \"speechreceptionthreshold_srt_estimate_left\",\n",
    "  \"speechreceptionthreshold_srt_estimate_right\"\n",
    ")\n",
    "\n",
    "## preprocessing\n",
    "dat <- dat %>%\n",
    "  mutate(\n",
    "    tin_status = factor(tin_status),\n",
    "    sex = factor(sex),\n",
    "    loud_music_exposure_frequency = factor(loud_music_exposure_frequency),\n",
    "    noisy_workplace = factor(noisy_workplace),\n",
    "    hearing_aid_user = factor(hearing_aid_user),\n",
    "    hearing_difficultyproblems_with_background_noise =\n",
    "      factor(hearing_difficultyproblems_with_background_noise),\n",
    "    handedness_chiralitylaterality =\n",
    "      factor(handedness_chiralitylaterality),\n",
    "    alcohol_intake_frequency = factor(alcohol_intake_frequency),\n",
    "    average_total_household_income_before_tax =\n",
    "      factor(average_total_household_income_before_tax)\n",
    "  ) %>%\n",
    "  drop_na(all_of(c(\"tin_status\", match_vars)))\n",
    "\n",
    "## matching\n",
    "match_formula <- as.formula(\n",
    "  paste(\"tin_status ~\", paste(match_vars, collapse = \" + \"))\n",
    ")\n",
    "m.out <- matchit(\n",
    "  formula = match_formula,\n",
    "  data = dat,\n",
    "  method = \"nearest\",\n",
    "  ratio = 1,\n",
    "  caliper = 0.2,\n",
    "  replace = FALSE\n",
    ")\n",
    "\n",
    "# saving the matched dataset\n",
    "matched_index <- rownames(match.data(m.out))\n",
    "matched_data <- dat[as.numeric(matched_index), ]\n",
    "write.csv(matched_data, \"ukb_demographics_matched.csv\", row.names = FALSE)\n",
    "\n",
    "\n",
    "## plotting\n",
    "# quartz()\n",
    "# summary(m.out)\n",
    "# plot(m.out)\n",
    "# plot(m.out, type = \"jitter\", interactive = FALSE)\n",
    "plot(m.out, type = \"density\", interactive = FALSE,\n",
    "     which.xs = ~age + sex)\n",
    "\n",
    "## stat summery\n",
    "summary_tbl <- matched_data %>%\n",
    "    select(tin_status, age, sex) %>%\n",
    "    tbl_summary(\n",
    "        by = tin_status,\n",
    "        statistic = list(\n",
    "            all_continuous() ~ \"{mean} Â± {sd}\",\n",
    "            all_categorical() ~ \"{n} ({p}%)\"\n",
    "        ),\n",
    "        digits = all_continuous() ~ 1\n",
    "    ) %>%\n",
    "    add_p() %>%\n",
    "    bold_labels()\n",
    "\n",
    "summary_tbl %>%\n",
    "  as_gt() %>%\n",
    "  gt::gtsave(\"summary_table.html\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!dx upload ukb_demographics_matched.csv --dest / \n",
    "!dx upload summary_table.html --dest / "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "## plotting distribution\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "df_matched = pd.read_csv(\"ukb_demographics_matched.csv\")\n",
    "df_plot = df_matched[[\"age\", \"sex\", \"tin_status\"]]\n",
    "\n",
    "df_plot[\"sex\"] = df_plot[\"sex\"].map({0: \"Female\", 1: \"Male\"})\n",
    "df_plot[\"tin_status\"] = df_plot[\"tin_status\"].map({0: \"Control\", 1: \"Tinnitus\"})\n",
    "\n",
    "pal = [\n",
    "        sns.cubehelix_palette(3, rot=-.2, light=.7).as_hex()[1],\n",
    "        sns.color_palette(\"ch:s=-.2,r=.3\", as_cmap=False).as_hex()[2]\n",
    "]\n",
    "\n",
    "xlim = [5, 80]\n",
    "bw_adjust = 1\n",
    "hues = [\"tin_status\", \"sex\"]\n",
    "pals = []\n",
    "for hue in hues:\n",
    "        g = sns.FacetGrid(\n",
    "                df_plot, hue=hue, aspect=3.5, height=1.6,\n",
    "                palette=pal, xlim=xlim\n",
    "        )\n",
    "\n",
    "        g.map(sns.kdeplot, \"age\", bw_adjust=bw_adjust, clip_on=False, clip=xlim,\n",
    "                fill=True, alpha=0.6, linewidth=1.5)\n",
    "        g.map(sns.kdeplot, \"age\", clip_on=False, color=\"w\", clip=xlim,\n",
    "                lw=1.5, bw_adjust=bw_adjust)\n",
    "        g.refline(y=0, linewidth=2, linestyle=\"-\", color=None, clip_on=False)\n",
    "\n",
    "        g.figure.subplots_adjust(hspace=.15, top=0.72)\n",
    "        g.set_titles(\"\")\n",
    "        g.add_legend(title=\"\")\n",
    "        g.set(yticks=[], ylabel=\"\", xlabel=r\"age\")\n",
    "        g.despine(bottom=True, left=True)\n",
    "        g.figure.savefig(f\"{hue}_distribution.pdf\", \n",
    "                        format=\"pdf\",       \n",
    "                        dpi=300,            \n",
    "                        bbox_inches=\"tight\"\n",
    "                        )\n",
    "        \n",
    "!dx upload sex_distribution.pdf --dest / \n",
    "!dx upload tin_status_distribution.pdf --dest / "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Work on matched dataframe and get full MRI data from UKB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "## run the first 3 cells again (to initiate spark ...)\n",
    "import pandas as pd\n",
    "\n",
    "## load the data\n",
    "df_matched = pd.read_csv(\"ukb_demographics_matched.csv\")\n",
    "subject_ids = df_matched[\"subject_id\"].values.tolist()\n",
    "ids_sql = \",\".join(map(str, subject_ids))\n",
    "\n",
    "def get_field_ids(keyword):\n",
    "    field_ids = [\n",
    "                    str(\n",
    "                    fields_by_title_keyword(fn)[0]\n",
    "                    ).split('\"')[1]\n",
    "                    for fn in field_titles_by_title_keyword(keyword)\n",
    "                    ]\n",
    "    \n",
    "    return field_ids\n",
    "\n",
    "vol_field_ids = ['eid'] + get_field_ids('Volume of')\n",
    "thickness_field_ids = ['eid'] + get_field_ids('Mean thickness of')\n",
    "area_field_ids = ['eid'] + get_field_ids('Area of')\n",
    "\n",
    "print(f\"********* getting volume information ***********\")\n",
    "df = participant.retrieve_fields(\n",
    "    names=vol_field_ids,\n",
    "    engine=dxdata.connect()\n",
    ")\n",
    "\n",
    "df_subset = df.filter(f\"eid IN ({ids_sql})\")\n",
    "df_subset.toPandas().to_csv('ukb_vol.csv', index=False)\n",
    "!dx upload ukb_vol.csv --dest / \n",
    "\n",
    "print(f\"********* getting thickness information ***********\")\n",
    "df = participant.retrieve_fields(\n",
    "    names=thickness_field_ids,\n",
    "    engine=dxdata.connect()\n",
    ")\n",
    "\n",
    "df_subset = df.filter(f\"eid IN ({ids_sql})\")\n",
    "df_subset.toPandas().to_csv('ukb_thickness.csv', index=False)\n",
    "!dx upload ukb_thickness.csv --dest / \n",
    "\n",
    "print(f\"********* getting area information ***********\")\n",
    "df = participant.retrieve_fields(\n",
    "    names=area_field_ids,\n",
    "    engine=dxdata.connect()\n",
    ")\n",
    "\n",
    "df_subset = df.filter(f\"eid IN ({ids_sql})\")\n",
    "df_subset.toPandas().to_csv('ukb_area.csv', index=False)\n",
    "!dx upload ukb_area.csv --dest / \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
